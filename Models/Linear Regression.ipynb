{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Linear Regression.ipynb","provenance":[],"authorship_tag":"ABX9TyPedWUfAJ8Kzr6p3i+qCaDO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93g5j8fVJYKT","executionInfo":{"status":"ok","timestamp":1639080917776,"user_tz":-120,"elapsed":3498,"user":{"displayName":"deeplearning cnn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfSGvuWMXwPAlEDo15swG8mDD2H9zk88g8EuLo=s64","userId":"11133293341965020187"}},"outputId":"dcc58349-71b5-4d13-dc49-b39c3715ebd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"]},{"cell_type":"markdown","source":["# **linear_model import LinearRegression**"],"metadata":{"id":"_Ip_VvQWMYfH"}},{"cell_type":"code","source":["from sklearn.datasets import load_boston\n","dataset= load_boston()\n","features= dataset.data\n","targets= dataset.target\n"],"metadata":{"id":"0pCbkNggP_eP","executionInfo":{"status":"ok","timestamp":1639080947949,"user_tz":-120,"elapsed":360,"user":{"displayName":"deeplearning cnn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfSGvuWMXwPAlEDo15swG8mDD2H9zk88g8EuLo=s64","userId":"11133293341965020187"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"52fd8803-a16b-4f60-f58c-23af72e34d21"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test= train_test_split(features,targets,test_size=0.3, random_state= 44, shuffle= True)\n","print('X_train is ',X_train.shape)\n","print('X_test is ',X_test.shape)\n","print('y_train is ',y_train.shape)\n","print('y_test is ',y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BjcgZ4NSt9tk","executionInfo":{"status":"ok","timestamp":1639080955562,"user_tz":-120,"elapsed":559,"user":{"displayName":"deeplearning cnn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfSGvuWMXwPAlEDo15swG8mDD2H9zk88g8EuLo=s64","userId":"11133293341965020187"}},"outputId":"e6ce2883-76d5-42e4-8d7f-ff152095c535"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train is  (354, 13)\n","X_test is  (152, 13)\n","y_train is  (354,)\n","y_test is  (152,)\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","\n","lr = LinearRegression(fit_intercept=True, normalize=True,copy_X=True,n_jobs=-1)\n"," # fit_intercept :حساب قيمة التقاطع مع محور اكس\n","lr.fit(X_train, y_train)\n","print(lr.score(X_train, y_train),'\\n')\n","print(lr.score(X_test, y_test),'\\n')\n","y_pred= lr.predict(X_test)\n","print('======================')\n","print('y_pred is', y_pred.shape)\n","print(y_pred[:5])\n","print('======================')\n","print(y_test[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aY45xK9FMZI_","executionInfo":{"status":"ok","timestamp":1639080962588,"user_tz":-120,"elapsed":385,"user":{"displayName":"deeplearning cnn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfSGvuWMXwPAlEDo15swG8mDD2H9zk88g8EuLo=s64","userId":"11133293341965020187"}},"outputId":"dc59aa97-0f48-4bda-e559-647d10b1d41c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7293698153057147 \n","\n","0.7532417995961491 \n","\n","======================\n","y_pred is (152,)\n","[17.72068078 25.18230573 21.70246845 36.15306445 13.73291424]\n","======================\n","[17.8 21.5 21.2 32.4 10.9]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","error= mean_absolute_error(y_test,y_pred,multioutput='uniform_average') \n","print(error)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUQ23c9V1Z1j","executionInfo":{"status":"ok","timestamp":1639080980882,"user_tz":-120,"elapsed":334,"user":{"displayName":"deeplearning cnn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfSGvuWMXwPAlEDo15swG8mDD2H9zk88g8EuLo=s64","userId":"11133293341965020187"}},"outputId":"7ec1306e-59ab-4070-c15d-2f15e9f1ea6e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["3.43186932227615\n"]}]},{"cell_type":"markdown","source":["# **Ridge Regression**"],"metadata":{"id":"ACV5t_M80nUC"}},{"cell_type":"code","source":["from sklearn.linear_model import Ridge\n","LRridge= Ridge(alpha=0.2,random_state= 33)\n","LRridge.fit(X_train, y_train)\n","print(LRridge.score(X_train,y_train))\n","print(LRridge.score(X_test,y_test))\n","y_pred=LRridge.predict(X_test)\n","print('======================')\n","print(y_pred[:5])\n","print('======================')\n","print(y_test[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"by9mPU2F010a","executionInfo":{"status":"ok","timestamp":1639081122249,"user_tz":-120,"elapsed":9,"user":{"displayName":"deeplearning cnn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfSGvuWMXwPAlEDo15swG8mDD2H9zk88g8EuLo=s64","userId":"11133293341965020187"}},"outputId":"707ea3fb-cd65-4041-d4d0-f708194772cf"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7289646521093622\n","0.7548537221289422\n","======================\n","[17.70402127 24.910565   21.64115818 36.03033479 13.86051403]\n","======================\n","[17.8 21.5 21.2 32.4 10.9]\n"]}]},{"cell_type":"markdown","source":["# **Lasso Regression**"],"metadata":{"id":"SMZKGgld4Dgz"}},{"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","Lrlasso= Lasso(alpha=0.005, random_state=33)\n","Lrlasso.fit(X_train, y_train)\n","print(Lrlasso.score(X_train,y_train))\n","print(Lrlasso.score(X_test,y_test))\n","y_pred=Lrlasso.predict(X_test)\n","print('======================')\n","print(y_pred[:5])\n","print('======================')\n","print(y_test[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"URnMk4Cy4GOi","executionInfo":{"status":"ok","timestamp":1639081169934,"user_tz":-120,"elapsed":300,"user":{"displayName":"deeplearning cnn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfSGvuWMXwPAlEDo15swG8mDD2H9zk88g8EuLo=s64","userId":"11133293341965020187"}},"outputId":"c881569c-919b-411a-e216-f4b74bd4a33e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["0.729253113419801\n","0.7540583518179096\n","======================\n","[17.71758767 24.98471389 21.67649007 36.02473692 13.80507148]\n","======================\n","[17.8 21.5 21.2 32.4 10.9]\n"]}]},{"cell_type":"markdown","source":["# **SGD Regressor**"],"metadata":{"id":"8NsvzvL967J3"}},{"cell_type":"code","source":["from sklearn.linear_model import SGDRegressor\n","SGDRegression = SGDRegressor(alpha=0.006,random_state=33,penalty='l1',loss = 'huber')\n","SGDRegression.fit(X_train, y_train)\n","print(SGDRegression.score(X_train,y_train))\n","print(SGDRegression.score(X_test,y_test))\n","y_pred=SGDRegression.predict(X_test)\n","print('======================')\n","print(y_pred[:5])\n","print('======================')\n","print(y_test[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5bnOrWt26-Zg","executionInfo":{"status":"ok","timestamp":1639083770991,"user_tz":-120,"elapsed":525,"user":{"displayName":"deeplearning cnn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfSGvuWMXwPAlEDo15swG8mDD2H9zk88g8EuLo=s64","userId":"11133293341965020187"}},"outputId":"5055f352-da3f-4b11-b431-97a4b3b45fb0"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["0.3303062635314903\n","0.29374664789278493\n","======================\n","[19.46739518 20.59365889 19.35490074 25.73236676  5.48123201]\n","======================\n","[17.8 21.5 21.2 32.4 10.9]\n"]}]},{"cell_type":"markdown","source":["# **Example with one variable**"],"metadata":{"id":"Y7qnocCqNTJ_"}},{"cell_type":"code","source":["import numpy as np\n","\n","X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n","\n","y = np.dot(X, np.array([1, 2])) + 3  # y = 1 * x_0 + 2 * x_1 + 3\n","print(X,'\\n',y)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZLCOF6WKNaz9","executionInfo":{"status":"ok","timestamp":1639083803444,"user_tz":-120,"elapsed":363,"user":{"displayName":"deeplearning cnn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfSGvuWMXwPAlEDo15swG8mDD2H9zk88g8EuLo=s64","userId":"11133293341965020187"}},"outputId":"48368f22-2cf6-4be8-9224-d62877657c4f"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 1]\n"," [1 2]\n"," [2 2]\n"," [2 3]] \n"," [ 6  8  9 11]\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","lr=LinearRegression(fit_intercept=True, normalize=True)\n","lr.fit(X,y)\n","y_pred=lr.predict(np.array([[3, 3]]))\n","print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qrm7CThVQNY0","executionInfo":{"status":"ok","timestamp":1639083807067,"user_tz":-120,"elapsed":331,"user":{"displayName":"deeplearning cnn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfSGvuWMXwPAlEDo15swG8mDD2H9zk88g8EuLo=s64","userId":"11133293341965020187"}},"outputId":"cd2579c0-a869-40dc-ad0a-d39aa14738a3"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["[12.]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","\n","  FutureWarning,\n"]}]}]}